#!/usr/bin/env python3
"""
Comprehensive comparison of all prompt versions
"""

import sys
import os
import json
import time
from datetime import datetime

# Add src directory to Python path
sys.path.insert(0, 'src')

from slug_generator import SlugGenerator

def test_all_prompt_versions():
    """Test all prompt versions on expanded dataset"""
    
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ No OPENAI_API_KEY found")
        return
    
    # Expanded test cases covering various scenarios
    test_cases = [
        {
            "title": "è‹±åœ‹å¿…è²·ç«¥è£ JoJo Maman BÃ©bÃ©å®˜ç¶² 3 æŠ˜èµ·å…¥æ‰‹ç¶²è³¼æ•™å­¸",
            "expected_themes": ["uk", "baby", "clothes", "shopping", "guide"],
            "category": "brand-product-association"
        },
        {
            "title": "Kindleé›»å­æ›¸é–±è®€å™¨æœ€å¼·æ”»ç•¥ï¼šPaper Whiteã€Colorsoftç­‰å‹è™Ÿåˆ†åˆ¥ã€åƒ¹æ ¼æ¯”è¼ƒåŠç¶²è³¼é›†é‹æ•™å­¸",
            "expected_themes": ["kindle", "ereader", "comparison", "guide"],
            "category": "product-recognition"
        },
        {
            "title": "é–‹å­¸å­£ä»£è³¼å¿…è²·æ¸…å–®ï¼IFMEè¿”å­¸é‹ã€GregoryèƒŒå›ŠåŠé›»å­æ–‡å…·ç”¢å“ä½è‡³3æŠ˜",
            "expected_themes": ["school", "season", "shoes", "bags"],
            "category": "seasonal-content"
        },
        {
            "title": "GAPé›†åœ˜ç¾åœ‹å®˜ç¶²ç¶²è³¼æ•™å­¸ï¼Œé™„Old Navyã€Banana RepublicåŠAthletaç­‰å‰¯ç‰Œå…¨é¢ä»‹ç´¹",
            "expected_themes": ["gap", "us", "fashion", "brands"],
            "category": "fashion-brands"
        },
        {
            "title": "æ‰“é¢¨è½é›¨å¿…å‚™ï¼PROTECT Uã€FloatusåŠWpc.ç­‰è¶…å¼·é˜²é¢¨/è·£æ°´/é™æº«é›¨å‚˜æ¨‚å¤©ç¶²è³¼æ•™å­¸",
            "expected_themes": ["umbrella", "japan", "rakuten", "weather"],
            "category": "platform-product"
        },
        {
            "title": "æ—¥æœ¬æ¨‚å¤©æ™‚å°šç‰¹åƒ¹1æŠ˜æ€éº¼è²·ï¼ŸNBã€BEAMSç­‰ç”·å¥³ã€ç«¥è£å„ªæƒ åˆé›†åŠé›†é‹æ•™å­¸",
            "expected_themes": ["japan", "rakuten", "fashion", "sale"],
            "category": "marketplace-fashion"
        },
        {
            "title": "8å¤§æ—¥ç‰Œè¼•ç å¯¶å“ç‰Œä¸€æ¬¡ç‡ï¼Ageteã€nojessåŠStar Jewelryç­‰æ—¥åŠ‡å¥³ä¸»å¾¡ç”¨æ˜æ˜Ÿç å¯¶",
            "expected_themes": ["japanese", "jewelry", "brands", "guide"],
            "category": "luxury-brands"
        }
    ]
    
    versions = ["v1", "v2", "v3"]
    results = {}
    
    print("ğŸ”¬ COMPREHENSIVE PROMPT COMPARISON")
    print("="*80)
    print(f"Testing {len(test_cases)} cases across {len(versions)} prompt versions")
    print()
    
    for version in versions:
        print(f"ğŸ§ª Testing Prompt Version: {version}")
        
        # Create generator with specific prompt version
        generator = SlugGenerator(api_key=api_key, max_retries=2)
        
        if version == "v1":
            # Use original prompt
            def load_v1_prompt(prompt_name):
                with open("config/prompts/slug_generation.txt", 'r') as f:
                    return f.read().strip()
            generator._load_prompt = load_v1_prompt
        elif version == "v2":
            def load_v2_prompt(prompt_name):
                with open("config/prompts/slug_generation_v2.txt", 'r') as f:
                    return f.read().strip()
            generator._load_prompt = load_v2_prompt
        elif version == "v3":
            def load_v3_prompt(prompt_name):
                with open("config/prompts/slug_generation_v3.txt", 'r') as f:
                    return f.read().strip()
            generator._load_prompt = load_v3_prompt
        
        version_results = []
        total_coverage = 0
        successful = 0
        
        for i, case in enumerate(test_cases, 1):
            try:
                start_time = time.time()
                result = generator.generate_slug_from_content(
                    case['title'], 
                    f"Blog post about {case['category']}", 
                    count=2
                )
                duration = time.time() - start_time
                
                # Calculate coverage
                expected = set(case['expected_themes'])
                all_slugs = [result['primary']] + result.get('alternatives', [])
                slug_text = ' '.join(all_slugs).lower()
                
                matched = set()
                for theme in expected:
                    if theme.lower() in slug_text:
                        matched.add(theme)
                
                coverage = len(matched) / len(expected)
                total_coverage += coverage
                successful += 1
                
                version_results.append({
                    'case_id': i,
                    'category': case['category'],
                    'primary_slug': result['primary'],
                    'alternatives': result.get('alternatives', []),
                    'expected_themes': list(expected),
                    'matched_themes': list(matched),
                    'theme_coverage': coverage,
                    'duration': duration
                })
                
                print(f"   {i}. {case['category']}: {result['primary']} ({coverage:.1%})")
                
            except Exception as e:
                print(f"   {i}. {case['category']}: âŒ Error - {str(e)[:50]}...")
                version_results.append({
                    'case_id': i,
                    'category': case['category'],
                    'error': str(e),
                    'duration': 0
                })
        
        avg_coverage = total_coverage / len(test_cases) if test_cases else 0
        
        results[version] = {
            'avg_coverage': avg_coverage,
            'successful': successful,
            'total': len(test_cases),
            'results': version_results
        }
        
        print(f"   ğŸ“Š Summary: {successful}/{len(test_cases)} success, {avg_coverage:.1%} avg coverage")
        print()
        time.sleep(1)  # Brief pause between versions
    
    # Generate comprehensive comparison
    print("="*80)
    print("ğŸ“Š FINAL COMPARISON RESULTS")
    print("="*80)
    
    print("ğŸ† Performance Ranking:")
    sorted_versions = sorted(results.keys(), key=lambda v: results[v]['avg_coverage'], reverse=True)
    
    for i, version in enumerate(sorted_versions, 1):
        result = results[version]
        success_rate = result['successful'] / result['total']
        print(f"   {i}. {version}: {result['avg_coverage']:.1%} coverage, {success_rate:.0%} success")
    
    best_version = sorted_versions[0]
    baseline_version = "v1"
    
    if best_version != baseline_version:
        improvement = results[best_version]['avg_coverage'] - results[baseline_version]['avg_coverage']
        print(f"\nğŸ“ˆ Improvement: {best_version} vs {baseline_version}: +{improvement:.1%} coverage")
    
    # Category-wise analysis
    print(f"\nğŸ¯ Category Performance (Best Version: {best_version}):")
    best_results = results[best_version]['results']
    
    for result in best_results:
        if 'error' not in result:
            print(f"   {result['category']}: {result['theme_coverage']:.1%} - {result['primary_slug']}")
            if result['theme_coverage'] < 1.0:
                missing = set(result['expected_themes']) - set(result['matched_themes'])
                print(f"      Missing: {', '.join(missing)}")
    
    # Save comprehensive results
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f"results/comprehensive_prompt_comparison_{timestamp}.json"
    
    os.makedirs('results', exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': timestamp,
            'test_cases': len(test_cases),
            'versions_tested': versions,
            'results': results,
            'best_version': best_version,
            'improvement_over_baseline': results[best_version]['avg_coverage'] - results[baseline_version]['avg_coverage']
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ Detailed results saved to: {output_file}")
    
    return results

if __name__ == "__main__":
    test_all_prompt_versions()