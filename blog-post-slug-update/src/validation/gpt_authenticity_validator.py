"""
GPT Authenticity Validator - Anti-Fake Analysis System

This system validates that slugs are genuinely generated by OpenAI GPT,
not simulated or hardcoded responses. Critical for preventing V11 disaster repeat.

Key Validation Methods:
1. API Call Tracing - Log actual OpenAI requests/responses
2. Response Fingerprinting - Detect patterns indicating real GPT behavior
3. Anti-Simulation Detection - Identify hardcoded or repeated responses
4. Temporal Analysis - Track response timing and variability
5. Content Coherence - Validate GPT-style reasoning and analysis
"""

import json
import hashlib
import time
import re
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import openai
from dataclasses import dataclass, asdict


@dataclass
class APICallTrace:
    """Complete trace of an OpenAI API call for authenticity validation"""
    timestamp: str
    request_hash: str
    response_hash: str
    model: str
    prompt_snippet: str  # First 100 chars of prompt for verification
    response_snippet: str  # First 100 chars of response
    response_time_ms: int
    token_count: Optional[int]
    confidence_scores: List[float]
    reasoning_present: bool
    analysis_present: bool


@dataclass
class GPTFingerprint:
    """Unique characteristics of genuine GPT responses"""
    has_reasoning: bool
    has_analysis_structure: bool
    response_variability: float  # 0-1 score of response uniqueness
    temporal_consistency: bool
    api_metadata_present: bool
    content_coherence_score: float


class GPTAuthenticityValidator:
    """Validates that slug generation responses are genuinely from OpenAI GPT"""
    
    def __init__(self):
        self.call_traces: List[APICallTrace] = []
        self.response_hashes: set = set()
        self.simulation_patterns = [
            # Common simulation indicators
            "hardcoded-response",
            "test-slug-",
            "mock-",
            "example-",
            "sample-",
        ]
    
    def trace_api_call(self, 
                      request_data: Dict, 
                      response_data: Dict, 
                      start_time: float,
                      end_time: float) -> APICallTrace:
        """
        Create a complete trace of an OpenAI API call for validation
        
        Args:
            request_data: The OpenAI API request
            response_data: The OpenAI API response  
            start_time: When the request started (time.time())
            end_time: When the response completed (time.time())
        """
        # Create request hash (for detecting repeated identical requests)
        request_str = json.dumps(request_data, sort_keys=True)
        request_hash = hashlib.sha256(request_str.encode()).hexdigest()[:16]
        
        # Create response hash (for detecting identical responses)
        response_str = json.dumps(response_data, sort_keys=True)
        response_hash = hashlib.sha256(response_str.encode()).hexdigest()[:16]
        
        # Extract key information
        prompt_snippet = str(request_data.get('messages', [{}])[-1].get('content', ''))[:100]
        response_content = response_data.get('choices', [{}])[0].get('message', {}).get('content', '')
        response_snippet = response_content[:100]
        
        # Parse slug response if it's JSON
        confidence_scores = []
        reasoning_present = False
        analysis_present = False
        
        try:
            if response_content.strip().startswith('{'):
                parsed_response = json.loads(response_content)
                
                # Extract confidence scores
                if 'slugs' in parsed_response:
                    confidence_scores = [
                        slug.get('confidence', 0) 
                        for slug in parsed_response['slugs'] 
                        if isinstance(slug, dict)
                    ]
                
                # Check for reasoning/analysis structure
                reasoning_present = any(
                    slug.get('reasoning') for slug in parsed_response.get('slugs', [])
                    if isinstance(slug, dict)
                )
                analysis_present = 'analysis' in parsed_response
                
        except (json.JSONDecodeError, TypeError, KeyError):
            pass
        
        trace = APICallTrace(
            timestamp=datetime.now().isoformat(),
            request_hash=request_hash,
            response_hash=response_hash,
            model=request_data.get('model', 'unknown'),
            prompt_snippet=prompt_snippet,
            response_snippet=response_snippet,
            response_time_ms=int((end_time - start_time) * 1000),
            token_count=response_data.get('usage', {}).get('total_tokens'),
            confidence_scores=confidence_scores,
            reasoning_present=reasoning_present,
            analysis_present=analysis_present
        )
        
        self.call_traces.append(trace)
        self.response_hashes.add(response_hash)
        
        return trace
    
    def validate_response_authenticity(self, response_content: str, trace: APICallTrace) -> GPTFingerprint:
        """
        Validate that a response is genuinely from GPT
        
        Returns a fingerprint with authenticity indicators
        """
        # 1. Check for simulation patterns
        has_simulation_patterns = any(
            pattern in response_content.lower() 
            for pattern in self.simulation_patterns
        )
        
        # 2. Analyze response structure
        has_reasoning = trace.reasoning_present
        has_analysis_structure = trace.analysis_present
        
        # 3. Calculate response variability (uniqueness)
        response_variability = self._calculate_response_variability(trace.response_hash)
        
        # 4. Check temporal consistency (reasonable response times)
        temporal_consistency = 500 <= trace.response_time_ms <= 30000  # 0.5s to 30s is reasonable
        
        # 5. Validate API metadata presence
        api_metadata_present = trace.token_count is not None and trace.token_count > 0
        
        # 6. Content coherence analysis
        content_coherence_score = self._analyze_content_coherence(response_content, trace)
        
        return GPTFingerprint(
            has_reasoning=has_reasoning,
            has_analysis_structure=has_analysis_structure,
            response_variability=response_variability,
            temporal_consistency=temporal_consistency,
            api_metadata_present=api_metadata_present,
            content_coherence_score=content_coherence_score
        )
    
    def _calculate_response_variability(self, response_hash: str) -> float:
        """
        Calculate how unique this response is compared to previous responses
        Higher = more unique = more likely genuine
        """
        if len(self.call_traces) <= 1:
            return 1.0
        
        # Check if this response hash appears in previous traces
        previous_hashes = [trace.response_hash for trace in self.call_traces[:-1]]
        
        if response_hash in previous_hashes:
            # Count how many times this response appeared
            duplicate_count = previous_hashes.count(response_hash)
            # More duplicates = lower variability
            return max(0.0, 1.0 - (duplicate_count * 0.5))
        
        # Unique response gets high variability score
        return 1.0
    
    def _analyze_content_coherence(self, response_content: str, trace: APICallTrace) -> float:
        """
        Analyze if the response content shows GPT-like coherence and structure
        """
        coherence_score = 0.0
        
        try:
            # For JSON responses, check structure
            if response_content.strip().startswith('{'):
                parsed = json.loads(response_content)
                
                # GPT responses should have proper JSON structure
                if isinstance(parsed, dict):
                    coherence_score += 0.2
                
                # Should have expected keys
                if 'slugs' in parsed:
                    coherence_score += 0.3
                
                # Slugs should have proper structure
                slugs = parsed.get('slugs', [])
                if isinstance(slugs, list) and len(slugs) > 0:
                    coherence_score += 0.2
                    
                    # Check individual slug structure
                    for slug_data in slugs:
                        if isinstance(slug_data, dict):
                            if 'slug' in slug_data and 'confidence' in slug_data:
                                coherence_score += 0.1
                            if 'reasoning' in slug_data and len(slug_data.get('reasoning', '')) > 10:
                                coherence_score += 0.2
                            break
                
            # Check for reasonable response time (GPT takes time to generate)
            if trace.response_time_ms > 1000:  # At least 1 second
                coherence_score += 0.1
                
        except (json.JSONDecodeError, TypeError, KeyError):
            # Non-JSON response - less coherent
            coherence_score = 0.1
        
        return min(coherence_score, 1.0)
    
    def is_response_authentic(self, fingerprint: GPTFingerprint) -> Tuple[bool, str]:
        """
        Determine if a response is authentic based on its fingerprint
        
        Returns (is_authentic, reason)
        """
        issues = []
        
        # Critical authenticity checks
        if not fingerprint.has_reasoning and not fingerprint.has_analysis_structure:
            issues.append("No reasoning or analysis structure - likely hardcoded")
        
        if fingerprint.response_variability < 0.5:
            issues.append("Low response variability - possible repeated/simulated response")
        
        if not fingerprint.temporal_consistency:
            issues.append("Unrealistic response timing - too fast or too slow")
        
        if not fingerprint.api_metadata_present:
            issues.append("Missing API metadata - no token count or usage info")
        
        if fingerprint.content_coherence_score < 0.4:
            issues.append("Low content coherence - doesn't match GPT response patterns")
        
        # Determine authenticity
        is_authentic = len(issues) == 0
        reason = "Authentic GPT response" if is_authentic else "; ".join(issues)
        
        return is_authentic, reason
    
    def generate_authenticity_report(self) -> Dict:
        """
        Generate a comprehensive report on all traced API calls and their authenticity
        """
        if not self.call_traces:
            return {"error": "No API calls traced"}
        
        authentic_count = 0
        suspicious_count = 0
        issues_summary = {}
        
        for trace in self.call_traces:
            # Re-construct response content for analysis
            response_content = f"Response hash: {trace.response_hash}"  # Placeholder
            fingerprint = GPTFingerprint(
                has_reasoning=trace.reasoning_present,
                has_analysis_structure=trace.analysis_present,
                response_variability=1.0,  # Simplified for report
                temporal_consistency=500 <= trace.response_time_ms <= 30000,
                api_metadata_present=trace.token_count is not None,
                content_coherence_score=0.8 if trace.reasoning_present else 0.3
            )
            
            is_authentic, reason = self.is_response_authentic(fingerprint)
            
            if is_authentic:
                authentic_count += 1
            else:
                suspicious_count += 1
                issues_summary[trace.timestamp] = reason
        
        return {
            "total_calls": len(self.call_traces),
            "authentic_calls": authentic_count,
            "suspicious_calls": suspicious_count,
            "authenticity_rate": authentic_count / len(self.call_traces) if self.call_traces else 0,
            "unique_responses": len(self.response_hashes),
            "issues_summary": issues_summary,
            "traces": [asdict(trace) for trace in self.call_traces[-5:]]  # Last 5 traces
        }
    
    def save_traces(self, filepath: str):
        """Save all traces to file for later analysis"""
        data = {
            "traces": [asdict(trace) for trace in self.call_traces],
            "response_hashes": list(self.response_hashes),
            "generated_at": datetime.now().isoformat()
        }
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2)
    
    def load_traces(self, filepath: str):
        """Load traces from file"""
        with open(filepath, 'r') as f:
            data = json.load(f)
        
        self.call_traces = [
            APICallTrace(**trace_data) 
            for trace_data in data.get('traces', [])
        ]
        self.response_hashes = set(data.get('response_hashes', []))


class TrackedSlugGenerator:
    """
    Wrapper around SlugGenerator that automatically tracks all API calls
    for authenticity validation
    """
    
    def __init__(self, slug_generator, validator: GPTAuthenticityValidator):
        self.generator = slug_generator
        self.validator = validator
        self.original_generate = slug_generator._generate_with_openai
        
        # Monkey patch to trace all API calls
        slug_generator._generate_with_openai = self._traced_generate_with_openai
    
    def _traced_generate_with_openai(self, title: str, content: str, count: int = 1):
        """
        Wrapped version that traces all OpenAI API calls for authenticity validation
        """
        # Prepare request data
        analysis_content = content[:self.generator.config.API_CONTENT_LIMIT] if content else ""
        prompt = self.generator._create_slug_prompt(title, analysis_content, count)
        
        request_data = {
            "model": self.generator.config.OPENAI_MODEL,
            "messages": [
                {"role": "system", "content": "You are an SEO expert specializing in creating URL-friendly blog post slugs for cross-border e-commerce content."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": self.generator.config.MAX_TOKENS,
            "temperature": self.generator.config.TEMPERATURE,
            "response_format": {"type": "json_object"}
        }
        
        # Make traced API call
        start_time = time.time()
        
        response = self.generator.client.chat.completions.create(**request_data)
        
        end_time = time.time()
        
        # Extract response data
        response_data = {
            "choices": [{
                "message": {
                    "content": response.choices[0].message.content
                }
            }],
            "usage": {
                "total_tokens": response.usage.total_tokens if response.usage else None
            }
        }
        
        # Trace the call
        trace = self.validator.trace_api_call(request_data, response_data, start_time, end_time)
        
        # Validate authenticity
        fingerprint = self.validator.validate_response_authenticity(
            response.choices[0].message.content, trace
        )
        
        is_authentic, reason = self.validator.is_response_authentic(fingerprint)
        
        if not is_authentic:
            print(f"⚠️  SUSPICIOUS RESPONSE DETECTED: {reason}")
            print(f"   Trace: {trace.timestamp} - {trace.response_hash}")
        
        # Continue with original processing
        return self.original_generate(title, content, count)


# Convenience function for easy integration
def create_validated_generator(api_key: str, prompt_version: str) -> Tuple[TrackedSlugGenerator, GPTAuthenticityValidator]:
    """
    Create a SlugGenerator with built-in GPT authenticity validation
    
    Returns (tracked_generator, validator) for testing and validation
    """
    from core.slug_generator import SlugGenerator
    
    base_generator = SlugGenerator(api_key=api_key, prompt_version=prompt_version)
    validator = GPTAuthenticityValidator()
    tracked_generator = TrackedSlugGenerator(base_generator, validator)
    
    return tracked_generator, validator