#!/usr/bin/env python3
"""
V11 Comprehensive 4-Version A/B Testing Script
Real LLM API testing with production data analysis
"""

import json
import random
import sys
import os
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

def load_production_urls():
    """Load URLs from production batch data for random selection"""
    production_file = Path(__file__).parent.parent / 'docs/archive/batch-processing-data/batch_data/production/batch_8000/comprehensive_url_database.json'
    
    if not production_file.exists():
        print(f"‚ùå Production file not found: {production_file}")
        return []
    
    try:
        with open(production_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        print(f"üìä Loaded production database: {len(data)} total URLs")
        
        # Extract URLs with titles for testing
        urls_with_titles = []
        for item in data:
            if isinstance(item, dict) and 'title' in item and 'url' in item:
                urls_with_titles.append({
                    'title': item['title'],
                    'url': item['url'],
                    'content': item.get('content', item['title'])  # Use title as content if no content
                })
        
        print(f"‚úÖ Found {len(urls_with_titles)} URLs with titles")
        return urls_with_titles
        
    except Exception as e:
        print(f"‚ùå Error loading production data: {e}")
        return []

def select_random_urls(all_urls, count=30):
    """Randomly select URLs from production dataset"""
    if len(all_urls) < count:
        print(f"‚ö†Ô∏è Only {len(all_urls)} URLs available, using all")
        return all_urls
    
    random.seed(42)  # Reproducible results
    selected = random.sample(all_urls, count)
    
    print(f"üé≤ Randomly selected {len(selected)} URLs for testing")
    return selected

def hand_pick_problematic_urls():
    """Hand-pick 10 problematic URLs targeting specific failure categories"""
    problematic_cases = [
        # Multi-brand failures (3+ brands)
        {
            "title": "Êó•ÈüìÂè∞7Â§ßÊâãÊ©üÊÆºÂìÅÁâåÊé®‰ªãÔºåSKINNIYDIP/iface/ÁäÄÁâõÁõæiPhone16/ProÊâãÊ©üÊÆºÁôªÂ†¥ÔºÅ",
            "url": "https://example.com/multi-brand-phone-cases",
            "content": "ÂÖ®Èù¢ÊØîËºÉSKINNIYDIP„ÄÅiface„ÄÅÁäÄÁâõÁõæÁ≠â7ÂÄãÊâãÊ©üÊÆºÂìÅÁâåÁöÑÁâπËâ≤",
            "category": "multi_brand_failure",
            "v11_target": "v11b",
            "challenge": "3+ brands with complex product context"
        },
        
        # Cultural subculture terms (new V11 capability)
        {
            "title": "Âú∞Èõ∑Á≥ªvsÈáèÁî¢ÂûãÈ¢®Ê†ºÂÆåÊï¥Â∞çÊØîÔºÅ2025Âπ¥ÊúÄÊñ∞ÊΩÆÊµÅÂàÜÊûê",
            "url": "https://example.com/jirai-kei-vs-ryousangata",
            "content": "Ê∑±ÂÖ•ÂàÜÊûêÂú∞Èõ∑Á≥ªÂíåÈáèÁî¢ÂûãÂÖ©Á®ÆÊó•Á≥ªÊôÇÂ∞öÈ¢®Ê†ºÁöÑÂ∑ÆÁï∞ÂíåÊê≠ÈÖçÊäÄÂ∑ß",
            "category": "cultural_subculture", 
            "v11_target": "v11b",
            "challenge": "V10 lacks subculture intelligence - jirai-kei, ryousangata"
        },
        
        # Pattern repetition victims (currently using ultimate/premium)
        {
            "title": "„ÄêÁµÇÊ•µÊîªÁï•„Äë‰∏ÄÁï™Ë≥ûË≥ºË≤∑ÂÆåÊï¥ÊïôÂ≠∏ÔºÅÊó•Êú¨ÂãïÊº´Âë®ÈÇäÊî∂ËóèÊåáÂçó",
            "url": "https://example.com/ultimate-ichiban-kuji-guide", 
            "content": "‰∏ÄÁï™Ë≥ûË≥ºË≤∑ÂÆåÊï¥ÊîªÁï•ÔºåÂæûÊñ∞ÊâãÂà∞Â∞àÂÆ∂ÁöÑÊî∂ËóèÊïôÂ≠∏",
            "category": "pattern_repetition_victim",
            "v11_target": "v11b", 
            "challenge": "Currently would use 'ultimate' - V11 must use alternatives"
        },
        
        # Complex service contexts (proxy + forwarding + official)
        {
            "title": "Â§ßÂúãËó•Â¶ùÈ¶ôÊ∏ØÂ∫óvsÊó•Êú¨‰ª£Ë≥ºvsÂÆòÁ∂≤Áõ¥ÈÄÅÂÆåÊï¥ÊØîËºÉÂàÜÊûê",
            "url": "https://example.com/daikoku-multi-service-comparison",
            "content": "ÊØîËºÉÂ§ßÂúãËó•Â¶ùÈ¶ôÊ∏ØÂØ¶È´îÂ∫ó„ÄÅÊó•Êú¨‰ª£Ë≥ºÊúçÂãô„ÄÅÂÆòÁ∂≤Áõ¥ÈÄÅÁöÑÂÑ™Áº∫Èªû",
            "category": "complex_service_context",
            "v11_target": "v11b",
            "challenge": "Multi-service comparison with brand + geography + service types"
        },
        
        # Simple content over-enhancement (should be V11a)
        {
            "title": "Tory BurchÊ∏õÂÉπÂÑ™ÊÉ†ÔºÅËã±ÂúãÁ∂≤Ë≥º‰ΩéËá≥3Êäò",
            "url": "https://example.com/tory-burch-discount",
            "content": "Tory BurchËã±ÂúãÂÆòÁ∂≤Ê∏õÂÉπÊ¥ªÂãïÔºåÊâãË¢ãÈûãÂ±•3ÊäòÂÑ™ÊÉ†",
            "category": "simple_over_enhancement",
            "v11_target": "v11a", 
            "challenge": "V10 might over-enhance simple discount info"
        },
        
        # Brand hierarchy confusion (parent + sub-brand)
        {
            "title": "Uniqlo UÁ≥ªÂàóvs‰∏ÄËà¨UniqloÁî¢ÂìÅÁ∑öÂ∑ÆÁï∞ÂÆåÊï¥ÂàÜÊûê",
            "url": "https://example.com/uniqlo-u-vs-regular",
            "content": "Ê∑±ÂÖ•ÊØîËºÉUniqlo UË®≠Ë®àÂ∏´Á≥ªÂàóËàá‰∏ÄËà¨UniqloÁî¢ÂìÅÁöÑÂ∑ÆÁï∞",
            "category": "brand_hierarchy_confusion",
            "v11_target": "v11b",
            "challenge": "Parent brand (Uniqlo) vs sub-brand (Uniqlo U) distinction"
        },
        
        # Geographic complexity (multi-region)
        {
            "title": "Ê®ÇÂ§©ÂÖ®ÁêÉÈÖçÈÄÅÊúçÂãôÔºöÊó•Êú¨‚ÜíÈ¶ôÊ∏Ø‚ÜíÂè∞ÁÅ£ËΩâÈÅãÂÆåÊï¥ÊïôÂ≠∏",
            "url": "https://example.com/rakuten-multi-region-shipping", 
            "content": "Ê®ÇÂ§©ÂúãÈöõÈÖçÈÄÅÊúçÂãôÔºåÊ∂µËìãÊó•Êú¨Âà∞È¶ôÊ∏ØÂÜçÂà∞Âè∞ÁÅ£ÁöÑËΩâÈÅãÊµÅÁ®ã",
            "category": "geographic_complexity",
            "v11_target": "v11b",
            "challenge": "Multi-region shipping flow with service complexity"
        },
        
        # Character archetype content (new V11 terms)
        {
            "title": "ÁóÖÂ¨åËßíËâ≤ÂÆåÊï¥ÂàÜÊûêÔºöÂãïÊº´ÊñáÂåñ‰∏≠ÁöÑÂøÉÁêÜÁâπÂæµÁ†îÁ©∂",
            "url": "https://example.com/yandere-character-analysis",
            "content": "Ê∑±ÂÖ•ÂàÜÊûêÁóÖÂ¨åËßíËâ≤Âú®ÂãïÊº´ÊñáÂåñ‰∏≠ÁöÑÂøÉÁêÜÁâπÂæµÂíåË°®ÁèæÊâãÊ≥ï",
            "category": "character_archetype",
            "v11_target": "v11b",
            "challenge": "V10 lacks yandere cultural archetype recognition"
        },
        
        # Fashion subculture (V11 new intelligence)
        {
            "title": "ËòøËéâÂ°îÊôÇÂ∞öÂÆåÊï¥ÊåáÂçóÔºöÂæûClassicÂà∞GothicÈ¢®Ê†ºÂÖ®Ëß£Êûê",
            "url": "https://example.com/lolita-fashion-guide",
            "content": "ËòøËéâÂ°îÊôÇÂ∞öÁöÑÂÆåÊï¥ÊåáÂçóÔºåÂåÖÂê´Classic„ÄÅSweet„ÄÅGothicÁ≠âÂêÑÁ®ÆÈ¢®Ê†º",
            "category": "fashion_subculture", 
            "v11_target": "v11b",
            "challenge": "V10 lacks lolita-fashion subculture recognition"
        },
        
        # Cross-border service comparison
        {
            "title": "Amazon JapanÂÆòÁ∂≤ vs Êó•Êú¨‰ª£Ë≥º vs ÈõÜÈÅãÊúçÂãôÂÆåÊï¥ÊØîËºÉ",
            "url": "https://example.com/amazon-japan-service-comparison",
            "content": "ÊØîËºÉAmazon JapanÂÆòÁ∂≤Áõ¥ÈÄÅ„ÄÅ‰ª£Ë≥ºÊúçÂãô„ÄÅÈõÜÈÅãÊúçÂãôÁöÑÂÑ™Áº∫Èªû",
            "category": "cross_border_service",
            "v11_target": "v11b", 
            "challenge": "Official vs proxy vs forwarding service comparison"
        }
    ]
    
    print(f"üéØ Hand-picked {len(problematic_cases)} problematic URLs:")
    for i, case in enumerate(problematic_cases, 1):
        print(f"{i:2d}. {case['category']:25s} -> {case['v11_target']}")
    
    return problematic_cases

def classify_content_complexity(title, content):
    """Classify content as simple (V11a) or complex (V11b)"""
    
    # Simple content indicators
    simple_indicators = [
        'Ê∏õÂÉπ', 'ÂÑ™ÊÉ†', 'ÊäòÊâ£', 'discount', 'ÂÖçÈÅã', 'free shipping', 
        'ÂÉπÊ†º', 'price', 'Ë≤ªÁî®', 'cost', 'ÈÅãÈÄÅ', 'shipping'
    ]
    
    # Complex content indicators  
    complex_indicators = [
        'ÂÆåÊï¥', 'Ë©≥Á¥∞', 'Ê∑±ÂÖ•', 'ÂÖ®Èù¢', 'ÊØîËºÉ', 'ÂàÜÊûê', 'ÊïôÂ≠∏', 'ÊîªÁï•',
        'vs', 'Â∞çÊØî', 'ÊåáÂçó', 'guide', 'Á≥ªÂàó', 'collection', 'È¢®Ê†º', 'style'
    ]
    
    # Multi-brand detection
    brand_count = 0
    brands = ['Uniqlo', 'SKINNIYDIP', 'iface', 'ÁäÄÁâõÁõæ', 'Tory Burch', 
              'Amazon', 'Â§ßÂúãËó•Â¶ù', 'Ê®ÇÂ§©', 'Daikoku']
    for brand in brands:
        if brand.lower() in title.lower() or brand.lower() in content.lower():
            brand_count += 1
    
    # Cultural complexity
    cultural_complex = any(term in title + content for term in [
        'Âú∞Èõ∑Á≥ª', 'ÈáèÁî¢Âûã', 'ÁóÖÂ¨å', 'ËòøËéâÂ°î', '‰∏ÄÁï™Ë≥û', 'jirai', 'ryousa', 'yandere'
    ])
    
    # Decision logic
    if brand_count >= 2 or cultural_complex or any(ind in title + content for ind in complex_indicators):
        return "v11b", "complex"
    elif any(ind in title + content for ind in simple_indicators):
        return "v11a", "simple"  
    else:
        return "v11a", "simple"  # Default to simple

def setup_testing_framework():
    """Setup the 4-version testing framework"""
    
    # Load production URLs
    all_urls = load_production_urls()
    if not all_urls:
        print("‚ùå No production URLs loaded, cannot proceed")
        return None, None
        
    # Select random 30 URLs
    random_urls = select_random_urls(all_urls, 30)
    
    # Hand-pick 10 problematic URLs
    problematic_urls = hand_pick_problematic_urls()
    
    # Classify all URLs for V11a/V11b routing
    test_cases = []
    
    print(f"\nüìä CLASSIFYING URLS FOR V11 ROUTING:")
    print("=" * 50)
    
    # Process random URLs
    for i, url_data in enumerate(random_urls, 1):
        v11_variant, complexity = classify_content_complexity(
            url_data['title'], url_data['content']
        )
        test_cases.append({
            'id': f"random_{i:02d}",
            'title': url_data['title'],
            'content': url_data['content'], 
            'url': url_data['url'],
            'source': 'random',
            'complexity': complexity,
            'v11_target': v11_variant
        })
    
    # Process problematic URLs
    for i, url_data in enumerate(problematic_urls, 1):
        test_cases.append({
            'id': f"problem_{i:02d}",
            'title': url_data['title'],
            'content': url_data['content'],
            'url': url_data['url'], 
            'source': 'problematic',
            'category': url_data['category'],
            'complexity': 'complex' if url_data['v11_target'] == 'v11b' else 'simple',
            'v11_target': url_data['v11_target'],
            'challenge': url_data['challenge']
        })
    
    # Print classification summary
    v11a_count = len([t for t in test_cases if t['v11_target'] == 'v11a'])
    v11b_count = len([t for t in test_cases if t['v11_target'] == 'v11b'])
    
    print(f"V11a (Simple): {v11a_count} cases")
    print(f"V11b (Complex): {v11b_count} cases") 
    print(f"Total: {len(test_cases)} test cases")
    
    return test_cases, {
        'versions': ['v6', 'v10', 'v11a', 'v11b'],
        'random_count': len(random_urls),
        'problematic_count': len(problematic_urls),
        'v11a_cases': v11a_count,
        'v11b_cases': v11b_count
    }

if __name__ == "__main__":
    print("üß™ V11 COMPREHENSIVE 4-VERSION TESTING FRAMEWORK")
    print("=" * 55)
    
    test_cases, framework_info = setup_testing_framework()
    
    if test_cases:
        print(f"\n‚úÖ TESTING FRAMEWORK READY:")
        print(f"üìã Test cases: {len(test_cases)}")
        print(f"üé≤ Random URLs: {framework_info['random_count']}")
        print(f"üéØ Problematic URLs: {framework_info['problematic_count']}")
        print(f"üîß V11a (Simple): {framework_info['v11a_cases']}")
        print(f"üöÄ V11b (Complex): {framework_info['v11b_cases']}")
        print(f"üìä Versions to test: {', '.join(framework_info['versions'])}")
        
        # Save test cases for actual execution
        output_file = Path(__file__).parent / 'v11_test_cases.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'test_cases': test_cases,
                'framework_info': framework_info
            }, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Test cases saved to: {output_file}")
        print(f"\nüöÄ READY FOR A/B TESTING EXECUTION!")
    else:
        print("‚ùå Failed to setup testing framework")